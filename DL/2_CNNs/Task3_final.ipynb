{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e32d1f",
   "metadata": {},
   "source": [
    "# Task 3: Tell-the-time Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "#from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d111fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the images and lables\n",
    "\n",
    "images = np.load('/content/drive/MyDrive/Colab Notebooks/images.npy', mmap_mode='r+')\n",
    "labels = np.load('/content/drive/MyDrive/Colab Notebooks/labels.npy', mmap_mode='r+')\n",
    "index_train = np.load('index_train_final.npy')    #these are the indexes of the training images in the dataset (valid for the periodic funtion and multi-head model)\n",
    "index_test = np.load('index_test_final.npy')      #these are the indexes of the testing images in the dataset (valid for the periodic funtion and multi-head model)\n",
    "\n",
    "#create the train, validation and test set \n",
    "#uncomment these lines in case you want to create a model on a new training set\n",
    "#i = int(len(images) * 0.8)   # we want a 80:20 split\n",
    "#index_list = np.arange(0, len(images), 1)\n",
    "#index_train = np.random.choice(index_list, size = i, replace = False)   #indexes of the training + validation set\n",
    "#index_test = np.delete(index_list, index_train)                         #indexes of the test set\n",
    "\n",
    "\n",
    "X_train, X_test = images[index_train] / 255.0, images[index_test] / 255.0    #normalize the input data\n",
    "X_valid, X_train = X_train[:1000], X_train[1000:]            #create 1000 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89403b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make input appropriate for CNN network --> we are dealing with greyscale images, so one channel is required only\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], 150, 150, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 150, 150, 1)\n",
    "x_valid = X_valid.reshape(X_valid.shape[0], 150, 150, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251561d8",
   "metadata": {},
   "source": [
    "### Treat the problem as a purely regression problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the label data such that it is appropriate for a regression problem \n",
    "\n",
    "hours = labels[:, 0]     #hour entry from the label\n",
    "minutes = labels[:, 1] / 60   #minute entry from the label, note we normalize it so that it is defined between 0 and 1\n",
    "reg_labels = hours + minutes   #these are the regression lables\n",
    "\n",
    "#Note we decided to normalize the labels here below, because otherwise our model doesn't learn\n",
    "y_train, y_test = reg_labels[index_train] / 12 , reg_labels[index_test] / 12    #define the targets for training and testing\n",
    "y_valid, y_train = y_train[:1000], y_train[1000:]                               #define the targets for validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8586af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the architecture of the model in this cell\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size = (3,  3), strides = 3,  activation = 'relu', input_shape=(150, 150, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Convolution2D(64, kernel_size = (1, 1), activation = 'relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))   \n",
    "\n",
    "\n",
    "\n",
    "#we define a customized loss function in order to ensure that network computes the 'common sense' error\n",
    "#example: if the prediction is 11:00 but the true time is 1:00, this loss function ensures that the error is\n",
    "# 2 hours, not 10 hours! Based on this error then the function computed the mse\n",
    "def loss_func(y_true, y_pred):\n",
    "    loss1 = tensorflow.math.reduce_mean(tensorflow.square(y_true - y_pred), axis = -1)\n",
    "    loss2 = tensorflow.math.reduce_mean(tensorflow.square(abs(y_true - y_pred) - 1), axis = -1)   #-1 instead of -12 since we normalized the labels to be between 0 and 1\n",
    "    l1 = tensorflow.linalg.norm(loss1)\n",
    "    l2 = tensorflow.linalg.norm(loss2)\n",
    "    return tensorflow.cond(tensorflow.less(l1, l2),lambda: loss1,lambda: loss2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#define a stopping condition \n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model \n",
    "history = model.fit(x_train, y_train, epochs=300, batch_size = 100, validation_data=(x_valid, y_valid), callbacks = [early_stop])\n",
    "\n",
    "#save history\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist_csv_file = 'regression_history'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist.to_csv(f)\n",
    "\n",
    "#save model \n",
    "model.save('Task3_models/regression_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess the performance of the model\n",
    "model.evaluate(x_test, y_test)\n",
    "y_pred = model.predict([x_test[:,:]])\n",
    "ht = np.floor(y_test * 12)\n",
    "mt = (y_test * 12 - ht) * 60\n",
    "true_time = 60 * ht + mt  #this is the true time expressed in minutes after 0:00\n",
    "\n",
    "h = np.floor(y_pred * 12)\n",
    "m = (y_pred * 12 - h) * 60\n",
    "pred_time = 60 * h + m    #this is the predicted time expressed in minutes after 0:00\n",
    "\n",
    "delta = np.zeros(len(h)) #will include the common sense error of each prediction\n",
    "#the loop will ensure that we measure the common sense error between the prediction and the true time \n",
    "for i in range(len(h)):\n",
    "    delta1 = abs(true_time[i] - pred_time[i])\n",
    "    delta2 = abs(true_time[i] - pred_time[i] - 720)\n",
    "    if delta1 < delta2:\n",
    "        diff = delta1\n",
    "    else:\n",
    "        diff = delta2\n",
    "    delta[i] = diff\n",
    "\n",
    "print('Average time difference is: ' + str(delta.sum() / len(h)) + ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38348c2",
   "metadata": {},
   "source": [
    "### Treat problem as a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b08634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the new labels list for classification problem --> in this we have 720 categories for each minute post 0:00\n",
    "\n",
    "labels_cat = np.zeros((18000, 720))   #list will store each label to its appropriate category\n",
    "for i in range(len(labels)):   #loop through each label\n",
    "    h = labels[i, 0]   #the hour\n",
    "    m = labels[i, 1]   #the minte\n",
    "    c = 60*h + m       #category to which the label should be assigned to \n",
    "    labels_cat[i, c] = 1\n",
    "\n",
    "labels_cat = np.argmax(labels_cat, axis = 1)  #each element of the list will be an integer between 0 and 719, where the integer corresponds to the category of the label\n",
    "\n",
    "#create the training, test and validation labels again\n",
    "y_train, y_test = labels_cat[index_train], labels_cat[index_test]\n",
    "y_valid, y_train = y_train[:1000], y_train[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846442a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the architecture of the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size = (3,  3),  activation = 'relu', input_shape=(150, 150, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Convolution2D(64, kernel_size = (1, 1), activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(720, activation = 'softmax'))    #use softmax since we use sparse_categorical_crossentropy as the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#train the model \n",
    "history = model.fit(x_train, y_train, epochs=300, batch_size = 100, validation_data=(x_valid, y_valid), callbacks = [early_stop])\n",
    "\n",
    "#save history\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist_csv_file = 'classification_history'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist.to_csv(f)\n",
    "\n",
    "#save model \n",
    "model.save('Task3_models/classification_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess the perfromance of the model \n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b523d3c",
   "metadata": {},
   "source": [
    "We realize that 720 categories is overkill for this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b535220",
   "metadata": {},
   "source": [
    "### Multi-head model\n",
    "\n",
    "We create a model consisting of two heads - one head for predicting hours and another for predicting minutes. The hour branch acts classification model while the minute branch acts as a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557f7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the labels so that they are appropriate for the multi-head model\n",
    "\n",
    "y_train, y_test = labels[index_train], labels[index_test]\n",
    "y_valid, y_train = y_train[:1000], y_train[1000:]\n",
    "\n",
    "yh_train = y_train[:, 0]          #training labels for hours\n",
    "ym_train = y_train[:, 1] / 60     #training labels for minutes\n",
    "yh_valid = y_valid[:, 0]          #validation labels for hours\n",
    "ym_valid = y_valid[:, 1] / 60     #validation labels for minutes\n",
    "yh_test = y_test[:, 0]          #test labels for hours\n",
    "ym_test = y_test[:, 1] / 60     #test labels for minutes\n",
    "#note we have normalized the minute labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de20e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the architecture of the model\n",
    "\n",
    "\n",
    "#base of the model\n",
    "inp = layers.Input(shape=(150, 150, 1))\n",
    "model = layers.Convolution2D(32, kernel_size = (3, 3), activation = 'relu')(inp)\n",
    "model = layers.MaxPooling2D(pool_size=2)(model)\n",
    "model = layers.Convolution2D(32, kernel_size = (3, 3), activation = 'relu')(model)\n",
    "model = layers.Convolution2D(32, kernel_size = (3, 3), activation = 'relu')(model)\n",
    "model = layers.MaxPooling2D(pool_size=2)(model)\n",
    "model = layers.Convolution2D(64, kernel_size = (3, 3), activation = 'relu')(model)\n",
    "model = layers.Convolution2D(64, kernel_size = (1, 1), activation = 'relu')(model)\n",
    "model = layers.Flatten()(model)\n",
    "\n",
    "#hour branch --> acts as classification model\n",
    "hour = layers.Dense(200, activation = 'relu')(model)\n",
    "hour = layers.Dropout(0.1)(hour)\n",
    "hour = layers.Dense(200, activation = 'relu')(hour)\n",
    "hour = layers.Dense(12, activation = 'softmax', name = 'hour')(hour)\n",
    "\n",
    "#minutes branch --> acts as regression model \n",
    "minute = layers.Dense(200, activation = 'relu')(model)\n",
    "minute = layers.Dense(200, activation = 'relu')(minute)\n",
    "minute = layers.Dense(200, activation = 'relu')(minute)\n",
    "minute = layers.Dropout(0.1)(minute)\n",
    "minute = layers.Dense(200, activation = 'relu')(minutel)\n",
    "minute = layers.Dense(1, activation = 'softplus', name = 'minute')(minute)\n",
    "\n",
    "#put all of the parts together\n",
    "model = tensorflow.keras.Model(inputs = inp, outputs=[hour, minute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a1a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model. Note a loss for each branch has to be defined\n",
    "\n",
    "model.compile(loss=['sparse_categorical_crossentropy', 'mse'], optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, [yh_train, ym_train], epochs=100, batch_size=100, validation_data=(x_valid, [yh_valid, ym_valid]),\n",
    "         callbacks = [early_stop])\n",
    "\n",
    "#save history\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist_csv_file = 'multi_head_history'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist.to_csv(f)\n",
    "\n",
    "#save model \n",
    "model.save('Task3_models/multi_head_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7360a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Task3_models/multi_head_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess the performance of the model \n",
    "\n",
    "model.evaluate(x_test, [yh_test, ym_test])\n",
    "\n",
    "y_pred = model.predict([x_test[:,:]])\n",
    "\n",
    "#same procedure as pefore when assessing the performance on the test set \n",
    "h = np.argmax(y_pred[0], axis = 1) \n",
    "ht = yh_test\n",
    "m = y_pred[1] * 60\n",
    "mt = ym_test * 60\n",
    "pred_time = 60 * h + m.T   #predicted time\n",
    "true_time = 60 * ht + mt   #true time\n",
    "dlist = []\n",
    "delta = np.zeros(len(h))\n",
    "for i in range(len(h)):\n",
    "    delta1 = abs(true_time[i] - pred_time[0, i])\n",
    "    delta2 = abs(abs(true_time[i] - pred_time[0, i]) - 720)\n",
    "    if delta1 < delta2:\n",
    "        diff = delta1\n",
    "        dlist.append(delta1)\n",
    "    else:\n",
    "        diff = delta2\n",
    "        dlist.append(delta2)\n",
    "    delta[i] = diff\n",
    "\n",
    "print('Average time difference is: ' + str(delta.sum() / len(h)) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the error distribution of the model\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8, 8))\n",
    "n, bins, patches = plt.hist(dlist, 360, density=False, facecolor='purple', alpha=0.75)\n",
    "ax.set_xlabel(r'$\\Delta$ t (minutes)', fontsize = 15)\n",
    "ax.set_ylabel('Occurance', fontsize = 15)\n",
    "ax.set_xlim(0, 100)\n",
    "#plt.savefig('time_distr_mutihead')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865526b8",
   "metadata": {},
   "source": [
    "### Model using Periodic Function\n",
    "\n",
    "In this we reformulate the hour ($y_h$) and minute ($y_m$) label in the following way:\n",
    "<br> $Y_h$ = cos($\\pi$/12 $y_h$) \n",
    "<br> $Y_m$ = cos($\\pi$/60 $y_m$) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d279ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions used to reformulate the labels \n",
    "\n",
    "def hours_periodic(h):\n",
    "    return np.cos(np.pi/12 * h)\n",
    "\n",
    "def minutes_periodic(m):\n",
    "    return np.cos(np.pi/60 * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformulate the labels using the periodic functions \n",
    "\n",
    "y_train, y_test = labels[index_train], labels[index_test]\n",
    "y_valid, y_train = y_train[:1000], y_train[1000:]\n",
    "\n",
    "#the new training, validataion and test labels\n",
    "y_train = np.transpose([hours_periodic(y_train[:, 0]), minutes_periodic(y_train[:, 1])])\n",
    "y_valid = np.transpose([hours_periodic(y_valid[:, 0]), minutes_periodic(y_valid[:, 1])])\n",
    "y_test = np.transpose([hours_periodic(y_test[:, 0]), minutes_periodic(y_test[:, 1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b993320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a custom activation function which is periodic for the output layer \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def cos(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "def my_function(x):\n",
    "    x = K.cos(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the architecture of the model \n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size = (2,  2), strides = 3,  activation = 'relu', input_shape=(150, 150, 1)))\n",
    "model.add(Convolution2D(32, kernel_size = (3,  3), activation = 'relu', input_shape=(150, 150, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Convolution2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Convolution2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(2, activation = my_function))  #last layer with a custom peridic activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e87845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model \n",
    "history = model.fit(x_train, y_train, epochs=300, batch_size = 100, validation_data=(x_valid, y_valid), callbacks = [early_stop])\n",
    "\n",
    "#save history\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist_csv_file = 'periodic_history'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist.to_csv(f)\n",
    "\n",
    "#save model \n",
    "model.save('Task3_models/periodic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case you want to test the model that is included in the submission\n",
    "model = keras.models.load_model('periodic_model.h5',  custom_objects={'my_function': my_function})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a689e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assess the performance of the model\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "y_pred = model.predict([x_test[:,:]])\n",
    "hour = np.round(np.arccos(y_pred[:, 0]) * 12 / np.pi)\n",
    "minute = np.arccos(y_pred[:, 1]) * 60 / np.pi\n",
    "pred = hour*60 + minute\n",
    "hour_t = np.arccos(y_test[:, 0]) * 12 / np.pi\n",
    "minute_t = np.arccos(y_test[:, 1]) * 60 / np.pi\n",
    "true = hour_t*60 + minute_t\n",
    "\n",
    "dlist = []  \n",
    "delta = 0\n",
    "for i in range(len(hour)):\n",
    "    delta1 = abs(pred[i] - true[i])\n",
    "    delta2 = abs(abs(pred[i] - true[i]) - 720)\n",
    "    if delta1<delta2:\n",
    "        dlist.append(delta1)\n",
    "        delta+=delta1\n",
    "    else:\n",
    "        dlist.append(delta2)\n",
    "        delta+=delta2\n",
    "delta = delta / len(hour)\n",
    "print('Average time difference is: ' + str(delta) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the error distribution of the model\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8, 8))\n",
    "n, bins, patches = plt.hist(dlist, 360, density=False, facecolor='purple', alpha=0.75)\n",
    "ax.set_xlabel(r'$\\Delta$ t (minutes)', fontsize = 15)\n",
    "ax.set_ylabel('Occurance', fontsize = 15)\n",
    "ax.set_xlim(0, 100)\n",
    "#plt.savefig('time_distr_mutihead')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
