{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Testing the impact of obfuscating data by randomly permuting all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zinamAN9nr9j"
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import tensorflow \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUvUnEkFybme"
   },
   "outputs": [],
   "source": [
    "# Function to create an MLP with permutated input data\n",
    "def mlp_permutation(dataset, save=False):\n",
    "  print('\\n', dataset)\n",
    "\n",
    "  # Dataset will be either the MNIST or fashion MNIST\n",
    "  if dataset == 'digits':\n",
    "    data = keras.datasets.mnist\n",
    "    class_names = ['Zero','One','Two','Three','Four','Five','Six','Seven',\\\n",
    "                   'Eight','Nine']\n",
    "\n",
    "  elif dataset == 'fashion':\n",
    "    data = keras.datasets.fashion_mnist\n",
    "    class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal',\\\n",
    "                   'Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "  # Collecting the data\n",
    "  (x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "  X_train = x_train.copy()\n",
    "  X_test = x_test.copy()\n",
    "\n",
    "  # Permutating the input data with a constant random seed\n",
    "  for i in range(len(X_train)):\n",
    "      np.random.seed(44)\n",
    "      X_train[i] = np.random.permutation(X_train[i])\n",
    "      \n",
    "  for i in range(len(X_test)):\n",
    "      np.random.seed(44)\n",
    "      X_test[i] = np.random.permutation(X_test[i])\n",
    "\n",
    "  # Scaling the pixel intensities\n",
    "  X_valid, X_train = X_train[:5000] / 255, X_train[5000:] / 255\n",
    "\n",
    "  # Creating validation set\n",
    "  y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "  # Creating the MLP \n",
    "  model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "    keras.layers.Dropout(0.2)]) \n",
    "  \n",
    "  # Compiling our MLP\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='RMSprop',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  # Training our MLP\n",
    "  history = model.fit(X_train, y_train, epochs=40, \n",
    "                      validation_data=(X_valid, y_valid))\n",
    "  \n",
    "  # Saving\n",
    "  if save==True:\n",
    "    savepath_d = '/content/drive/MyDrive/Colab Notebooks/savefiles_mnist_digits/'\n",
    "    savepath_f = '/content/drive/MyDrive/Colab Notebooks/savefiles_mnist_fashion/'\n",
    "\n",
    "    if dataset == 'digits':\n",
    "      savepath = savepath_d\n",
    "    else:\n",
    "      savepath = savepath_f  \n",
    "\n",
    "    filename = 'mlp_permutation'\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    with open(savepath + filename + '.csv', mode='w') as f:\n",
    "      hist_df.to_csv(f)\n",
    "\n",
    "    test_case = np.array(model.evaluate(X_test, y_test))\n",
    "    np.save(savepath + filename + '.npy', test_case)\n",
    "    with open(filename + '.npy', 'wb') as f:\n",
    "      np.save(f, test_case)\n",
    "\n",
    "  # Testing\n",
    "  print('\\n', model.evaluate(X_test, y_test))\n",
    "  \n",
    "  X_new = X_test[:3]\n",
    "  y_prob = model.predict(X_new)  \n",
    "  print(y_prob.round(2))\n",
    "\n",
    "  y_pred = np.argmax(model.predict(X_new), axis=1)\n",
    "  print(y_pred)\n",
    "\n",
    "  print('\\nPredictions:', np.array(class_names)[y_pred])\n",
    "\n",
    "  y_new = y_test[:3]\n",
    "  print('True labels:', np.array(class_names)[y_new])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiBg3C5t6i8E"
   },
   "outputs": [],
   "source": [
    "# Running our MLP permutation code\n",
    "mlp_digits_model = mlp_permutation('digits', save=True)\n",
    "mlp_fashion_model = mlp_permutation('fashion', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucs3AkOp6n0m"
   },
   "outputs": [],
   "source": [
    "# Function to create a CNN with permutated input data\n",
    "def cnn_permutation(dataset, save=False):\n",
    "  print('\\n', dataset)\n",
    "\n",
    "  # Dataset will be either the MNIST or fashion MNIST\n",
    "  if dataset == 'digits':\n",
    "    data = keras.datasets.mnist\n",
    "    class_names = ['Zero','One','Two','Three','Four','Five','Six','Seven',\\\n",
    "                   'Eight','Nine']\n",
    "\n",
    "  elif dataset == 'fashion':\n",
    "    data = keras.datasets.fashion_mnist\n",
    "    class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal',\\\n",
    "                   'Shirt','Sneaker','Bag','Ankle boot']\n",
    "\n",
    "  # Collecting the data \n",
    "  (x_train, y_train), (x_test, y_test) = data.load_data()\n",
    "  X_train = x_train.copy()\n",
    "  X_test = x_test.copy()\n",
    "\n",
    "  # Permutating the input data with a constant random seed\n",
    "  for i in range(len(X_train)):\n",
    "      np.random.seed(44)\n",
    "      X_train[i] = np.random.permutation(X_train[i])\n",
    "      \n",
    "  for i in range(len(X_test)):\n",
    "      np.random.seed(44)\n",
    "      X_test[i] = np.random.permutation(X_test[i])\n",
    "\n",
    "  # Scaling the pixel intensities\n",
    "  X_valid, X_train = X_train[:5000] / 255, X_train[5000:] / 255\n",
    "\n",
    "  # Creating validation set\n",
    "  y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "  # Reshaping\n",
    "  x_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "  x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "  x_valid = X_valid.reshape(X_valid.shape[0], 28, 28, 1)\n",
    "\n",
    "  # Creating our CNN \n",
    "  DefaultConv2D = partial(layers.Conv2D, kernel_size=3, activation='relu', \n",
    "                          padding=\"SAME\")\n",
    "  model = Sequential([\n",
    "      DefaultConv2D(filters=64, kernel_size=7, input_shape=(28,28,1)),\n",
    "      layers.MaxPooling2D(pool_size=2),\n",
    "      DefaultConv2D(filters=128),\n",
    "      DefaultConv2D(filters=128),\n",
    "      layers.MaxPooling2D(pool_size=2),\n",
    "      DefaultConv2D(filters=256),\n",
    "      DefaultConv2D(filters=256),\n",
    "      layers.MaxPooling2D(pool_size=2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(units=128, activation='relu'),\n",
    "      layers.Dropout(0.5),\n",
    "      layers.Dense(units=64, activation='relu'),\n",
    "      layers.Dropout(0.5),\n",
    "      layers.Dense(units=10, activation='softmax')])\n",
    "  \n",
    "  # Compiling our CNN\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='sgd',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  # Training our CNN\n",
    "  history = model.fit(X_train, y_train, epochs=40, \n",
    "                      validation_data=(x_valid, y_valid))\n",
    "\n",
    "  # Saving\n",
    "  if save==True:\n",
    "    savepath_d = '/content/drive/MyDrive/Colab Notebooks/cnn_mnist_digits/'\n",
    "    savepath_f = '/content/drive/MyDrive/Colab Notebooks/cnn_mnist_fashion/'\n",
    "\n",
    "    if dataset == 'digits':\n",
    "      savepath = savepath_d\n",
    "    else:\n",
    "      savepath = savepath_f  \n",
    "\n",
    "    filename = 'cnn_permutation'\n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    with open(savepath + filename + '.csv', mode='w') as f:\n",
    "      hist_df.to_csv(f)\n",
    "\n",
    "    test_case = np.array(model.evaluate(x_test, y_test))\n",
    "    np.save(savepath + filename + '.npy', test_case)\n",
    "    with open(filename + '.npy', 'wb') as f:\n",
    "      np.save(f, test_case)\n",
    "\n",
    "  # Testing\n",
    "  print('\\n', model.evaluate(x_test, y_test))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtGa3iM16o_0"
   },
   "outputs": [],
   "source": [
    "# Running our CNN permutation code\n",
    "cnn_digits_model = cnn_permutation('digits', save=True)\n",
    "cnn_fashion_model = cnn_permutation('fashion', save=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
